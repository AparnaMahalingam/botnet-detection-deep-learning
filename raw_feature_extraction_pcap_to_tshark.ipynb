{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw feature extraction script - from pcap files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated on: Mon, 04-30-2018\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "today = datetime.datetime.now()\n",
    "last_updated = \"Last updated on: \" + today.strftime(\"%a, %m-%d-%Y\")\n",
    "print(last_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_pcaps(pcap_filename):\n",
    "    \"\"\"Read the pcaps, split them into chunks of smaller-sized pcaps\"\"\"\n",
    "    \n",
    "    pcap_chunks = re.findall('(.+).pcap', pcap_filename)[0] + '_mb.pcap' # first element of the list returned by findall()\n",
    "    print(pcap_chunks)\n",
    "    \n",
    "    os.system(\"tcpdump -r \" + pcap_filename + \" -w \" + pcap_chunks + \" -C 50\") # auto-creates smaller chunks\n",
    "    small_pcaps = \"ls -t \" + pcap_chunks + \"* > little_pcaps.txt\" # enlists all the pcap chunks in a text file IN ORDER!!\n",
    "    print(small_pcaps)    \n",
    "    \n",
    "    os.system(small_pcaps) # in the shell\n",
    "    \n",
    "    littlecaps = 'little_pcaps.txt'\n",
    "    with open(littlecaps, 'r') as pcaplst:\n",
    "        if len(pcaplst.readlines()) >= 1:\n",
    "            return(littlecaps) # returns just the filename\n",
    "    # if it failed to split pcaps\n",
    "    return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_csv(pcap_filename):\n",
    "    \"\"\"Reads all the smaller-sized chunks and extracts all the necessary raw features into a csv file\"\"\"\n",
    "    \n",
    "    pcaplst = split_pcaps(pcap_filename) # first check if descriptor == 0\n",
    "    \n",
    "    if pcaplst == 0:\n",
    "        print(\"Could not extract features -- pcaps not found\")\n",
    "        return(False)\n",
    "    \n",
    "    pcaplst = open(split_pcaps(pcap_filename), 'r') # file must be opened\n",
    "    \n",
    "    pcaplst = pcaplst.read().splitlines() # ignores the ending '\\n' character\n",
    "    n_chunks = len(pcaplst)\n",
    "    print(n_chunks)\n",
    "    \n",
    "    if n_chunks != 0:\n",
    "        fcsv = re.findall('(.+).pcap', pcap_filename)[0] + '.csv'  # creates a ISCX_Botnet_Testing.csv\n",
    "        print(fcsv)\n",
    "        csv_traffic = open(fcsv, 'w+') # close file at the end!\n",
    "        for pcap in pcaplst[::-1]:\n",
    "            \n",
    "            '''Must install tshark for this to work.\n",
    "            ~$ sudo apt-get install tshark'''\n",
    "            \n",
    "            # extract features and convert to csv\n",
    "            os.system(\"tshark -nr \" + pcap + \" -T fields -e frame.number -t e -e _ws.col.Time -e ip.src -e ip.dst -e ip.proto -e ip.len -e ip.dsfield -e dns.count.answers -e tcp.dstport -e tcp.srcport -e frame.protocols -e ip.flags -e udp.length -e tcp.len -e tcp.seq -e tcp.nxtseq -e tcp.flags -e ip.geoip.dst_country -e ip.geoip.src_country -e ip.geoip.dst_lon -e ip.geoip.dst_lat -e ip.geoip.src_lon -e ip.geoip.src_lat -e ip.ttl -E header=y -E separator=, -E quote=d -E occurrence=f >> \" + fcsv)\n",
    "        csv_traffic.close()\n",
    "        return(fcsv)\n",
    "    else:\n",
    "        return('Error -- no smaller-sized pcaps created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aparna/Downloads'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISCX_Botnet_Testing_mb.pcap\n",
      "ls -t ISCX_Botnet_Testing_mb.pcap* > little_pcaps.txt\n",
      "44\n",
      "ISCX_Botnet_Testing.csv\n",
      "ISCX_Botnet_Testing.csv\n"
     ]
    }
   ],
   "source": [
    "# calling the functions on the pcap files\n",
    "print(extract_features_csv('ISCX_Botnet_Testing.pcap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
